{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://pydata.org/nyc2014/schedule/\" width=100% height=350></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"http://pydata.org/nyc2014/schedule/\" width=100% height=350></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for nyc2014 conference\n",
      "loading data for berlin2014 conference\n",
      "loading data for sv2014 conference\n",
      "loading data for ldn2014 conference\n",
      "loading data for nyc2013 conference\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "# past events\n",
    "# TODO: fetch this data from past events page\n",
    "conferences = ['nyc2014', 'berlin2014', 'sv2014', 'ldn2014', 'nyc2013']\n",
    "\n",
    "abstract_url = \"http://pydata.org/%s/abstracts/\"\n",
    "\n",
    "conf_data = {}\n",
    "\n",
    "# Collecting data about abstracts\n",
    "for conference in conferences:\n",
    "    print \"loading data for %s conference\" % conference\n",
    "    raw = urllib2.urlopen(abstract_url % conference).read()\n",
    "    soup = BeautifulSoup(raw)\n",
    "    abstracts = [abstract.get_text().strip() for abstract in soup.find_all(class_=\"accordion-inner\")]\n",
    "    titles = [title.get_text().strip() for title in soup.find_all(class_=\"accordion-toggle\")]\n",
    "#     speakers = [speaker.get_text().strip() for speaker in soup.select(\".accordion-heading h5 a\")]\n",
    "    \n",
    "    conf_data[conference] = {}\n",
    "    conf_data[conference]['abstracts'] = abstracts\n",
    "    conf_data[conference]['titles'] = titles\n",
    "#     conf_data[conference]['speakers'] = speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'(Easy), High Performance Text Processing with Rosetta',\n",
       " u'A Machine Learning Pipeline with Scikit-Learn',\n",
       " u'Advanced IPython Notebook Widgets',\n",
       " u'Advanced scikit-learn',\n",
       " u'Analyzing Satellite Images With Python Scientific Stack',\n",
       " u'Beautiful Interactive Visualizations in the Browser with Bokeh',\n",
       " u'Biological Data Science',\n",
       " u'Blaze Foundations: Part 1',\n",
       " u'Data Community/Meetup Organizers',\n",
       " u\"Data Science: It's Easy as Py\\u01c3\",\n",
       " u'Data warehouse and conceptual modelling with Cubes 1.0',\n",
       " u'Data-driven conversations about biology',\n",
       " u'Decreasing Uncertainty with Weakly Informative Priors and Penalized Regression',\n",
       " u'Disco: Distributed Multi-Stage Data Pipelines',\n",
       " u'Driving Blaze in the Real World of Data Land Mines',\n",
       " u'Evaluating skills in educational and other settings: An overview',\n",
       " u'From DataFrame to Web Application in 10 minutes',\n",
       " u'Get To Know Your Data',\n",
       " u'Grids, Streets & Pipelines: Making a linguistic streetmap with scikit-learn',\n",
       " u'Healthcare Analytics']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_data['nyc2014']['titles'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           abstracts  \\\n",
      "0                                                      \n",
      "1  The The Greater Plains Collaborative (GPC) is ...   \n",
      "2  To a lot of people, Facebook is a website for ...   \n",
      "3  The ad targeting team at Yelp is tasked with p...   \n",
      "4                                                      \n",
      "\n",
      "                                              titles conference city  year  \n",
      "0                                                        sv2014   sv  2014  \n",
      "1  Using Python and Paver to Control a Large Medi...     sv2014   sv  2014  \n",
      "2  A Full Stack Approach to Data Visualization: T...     sv2014   sv  2014  \n",
      "3                               Ad Targeting at Yelp     sv2014   sv  2014  \n",
      "4  Analyzing Satellite Images With Python Scienti...     sv2014   sv  2014  \n",
      "                                           abstracts  \\\n",
      "0  The Python data ecosystem has grown beyond the...   \n",
      "1  In this talk I will give an overview of Random...   \n",
      "2  Clustering data is a fundamental technique in ...   \n",
      "3  At Conversocial we use machine learning to fil...   \n",
      "4  At WIDE IO, we are specialists in image proces...   \n",
      "\n",
      "                                              titles conference city  year  \n",
      "0  Massively Parallel Processing with Procedural ...    ldn2014  ldn  2014  \n",
      "1  A Beginner's guide to Random Forests - R vs Py...    ldn2014  ldn  2014  \n",
      "2  A Full Stack Approach to Data Visualization: T...    ldn2014  ldn  2014  \n",
      "3  Adaptive Filtering of Tweets with Machine Lear...    ldn2014  ldn  2014  \n",
      "4        An introduction to video action recognition    ldn2014  ldn  2014  \n",
      "                                           abstracts  \\\n",
      "0  I'll walk you through Python's best tools for ...   \n",
      "1  An increasing amount of information is being c...   \n",
      "2  Scikit-learn is one of the most well-known mac...   \n",
      "3  Attendees will be given a practical introducti...   \n",
      "4                                       Coming soon.   \n",
      "\n",
      "                                              titles conference city  year  \n",
      "0  A practical introduction to IPython Notebook &...    nyc2013  nyc  2013  \n",
      "1                           Image Features in Python    nyc2013  nyc  2013  \n",
      "2  A Beginner’s Guide to Machine Learning with Sc...    nyc2013  nyc  2013  \n",
      "3  A practical introduction to Pandas with Citibi...    nyc2013  nyc  2013  \n",
      "4  An Intro to FOSS Licenses and Copyrights in Da...    nyc2013  nyc  2013  \n",
      "                                           abstracts  \\\n",
      "0  ABBY is a Django app that helps you manage you...   \n",
      "1  Python is quickly becoming the glue language w...   \n",
      "2                                                      \n",
      "3                                        Coming Soon   \n",
      "4  Learn how to program and utilize the parallel ...   \n",
      "\n",
      "                                           titles  conference    city  year  \n",
      "0  ABBY - A Django app to document your A/B tests  berlin2014  berlin  2014  \n",
      "1                Algorithmic Trading with Zipline  berlin2014  berlin  2014  \n",
      "2                                           Blaze  berlin2014  berlin  2014  \n",
      "3                   Building the PyData Community  berlin2014  berlin  2014  \n",
      "4                                 CUDA 6 Tutorial  berlin2014  berlin  2014  \n",
      "                                           abstracts  \\\n",
      "0  This talk covers rapid prototyping of a high p...   \n",
      "1  Scikit-Learn is one of the most popular machin...   \n",
      "2  IPython recently introduced a new framework fo...   \n",
      "3                                       Coming soon.   \n",
      "4  Python has a rich ecosystem of open source geo...   \n",
      "\n",
      "                                              titles conference city  year  \n",
      "0  (Easy), High Performance Text Processing with ...    nyc2014  nyc  2014  \n",
      "1      A Machine Learning Pipeline with Scikit-Learn    nyc2014  nyc  2014  \n",
      "2                  Advanced IPython Notebook Widgets    nyc2014  nyc  2014  \n",
      "3                              Advanced scikit-learn    nyc2014  nyc  2014  \n",
      "4  Analyzing Satellite Images With Python Scienti...    nyc2014  nyc  2014  \n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "pydata = DataFrame()\n",
    "\n",
    "for conf in conf_data:\n",
    "    conf_dataframe = DataFrame.from_dict(conf_data[conf])\n",
    "    conf_dataframe['conference'] = conf\n",
    "    conf_dataframe['city'] = conf[:-4]\n",
    "    conf_dataframe['year'] = int(conf[-4:])\n",
    "    \n",
    "    print DataFrame.head(conf_dataframe)\n",
    "    \n",
    "    pydata = pydata.append(conf_dataframe)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in dataframe 233\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstracts</th>\n",
       "      <th>titles</th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conference</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>berlin2014</th>\n",
       "      <td> 50</td>\n",
       "      <td> 50</td>\n",
       "      <td> 50</td>\n",
       "      <td> 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc2014</th>\n",
       "      <td> 50</td>\n",
       "      <td> 50</td>\n",
       "      <td> 50</td>\n",
       "      <td> 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv2014</th>\n",
       "      <td> 49</td>\n",
       "      <td> 49</td>\n",
       "      <td> 49</td>\n",
       "      <td> 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldn2014</th>\n",
       "      <td> 44</td>\n",
       "      <td> 44</td>\n",
       "      <td> 44</td>\n",
       "      <td> 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc2013</th>\n",
       "      <td> 40</td>\n",
       "      <td> 40</td>\n",
       "      <td> 40</td>\n",
       "      <td> 40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            abstracts  titles  city  year\n",
       "conference                               \n",
       "berlin2014         50      50    50    50\n",
       "nyc2014            50      50    50    50\n",
       "sv2014             49      49    49    49\n",
       "ldn2014            44      44    44    44\n",
       "nyc2013            40      40    40    40"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'records in dataframe %i' % len(pydata)\n",
    "pydata.groupby(['conference']).count(1).sort('year', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have all the data. Let's try to analyse it\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "text = {}\n",
    "words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_list = [\"ll\", \"II\", \"ll\", \"http\", \"://\", \"e\", \"g\", \"2\", \"0\"]\n",
    "\n",
    "for conference in conf_data:\n",
    "    raw = \" \".join(conf_data[conference]['abstracts'])\n",
    "    tokens = nltk.WordPunctTokenizer().tokenize(raw)\n",
    "    text[conference] = nltk.Text(tokens)\n",
    "    words[conference] = [w.lower() for w in text[conference] if w.lower() not in stop_list]\n",
    "    words[conference] = [w for w in words[conference] if w not in stop]\n",
    "    words[conference] = filter(lambda word: word not in u'%,-:()$\\/;?.’–“”*\\'[]', words[conference])\n",
    "    words[conference] = [w for w in words[conference] if w not in [\"ll\", \"II\", \"ll\", \"http\", \"://\", \"e\", \"g\", \"2\", \"0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv2014\n",
      "http ://; nearest neighbor; machine learning; Reference Model;\n",
      "neighbor algorithm; IPython Notebook; big data; open source; make\n",
      "predictions; data analysis; Big Data; github repository; current\n",
      "state; means clustering; visualization libraries; https ://; compiler\n",
      "optimizations; accepting payments; block fraud; concise construction\n",
      "None\n",
      "\n",
      "ldn2014\n",
      "http ://; machine learning; :// www; data processing; open source;\n",
      "Matrix Factorisation; certain types; public clouds; rent ratios;\n",
      "financial industry; PyData Boston; blocking technique; cloud\n",
      "computing; exact solution; includes two; presentation focuses; drug\n",
      "development; graphical plotting; quantum chemistry; wide range\n",
      "None\n",
      "\n",
      "berlin2014\n",
      "http ://; machine learning; Big Data; Quantified Self; self tracking;\n",
      "Semantic Web; Coming Soon; among others; open source; data analysis;\n",
      "case study; Hadoop jobs; :// www; working knowledge; predictive model;\n",
      "time permits; Add tranformations; Machine Learning; Operating System;\n",
      "Pythonista interested\n",
      "None\n",
      "\n",
      "nyc2013\n",
      "machine learning; Coming Soon; open source; IPython Notebook; Coming\n",
      "soon; chip design; broad range; face detection; file descriptor; https\n",
      "://; hue binning; resources needed; image features; talk covers;\n",
      "computer vision; oriented computations; future computation; CPython\n",
      "interpreter; analytics capabilities; sampling algorithms\n",
      "None\n",
      "\n",
      "nyc2014\n",
      "machine learning; open source; data science; Cloud Foundry; command\n",
      "line; Coming soon; time series; financial statements; New York; Time\n",
      "permitting; confidence pool; crafted artisanal; dimensionality\n",
      "reduction; gene expression; keep track; rapid prototyping; big data;\n",
      "http ://; style buildpack; web application\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for conference in text:\n",
    "    print conference\n",
    "    print text[conference].collocations()\n",
    "    print \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sv2014': 7462, 'ldn2014': 5859, 'nyc2013': 4328, 'berlin2014': 7633, 'nyc2014': 6293}\n",
      "{'sv2014': 1906, 'ldn2014': 1738, 'nyc2013': 1337, 'berlin2014': 1877, 'nyc2014': 1824}\n"
     ]
    }
   ],
   "source": [
    "numwords = {}\n",
    "uniwords = {}\n",
    "\n",
    "for conference in text:\n",
    "    numwords[conference] = len(text[conference])\n",
    "    uniwords[conference] = len(set(text[conference]))\n",
    "\n",
    "print numwords\n",
    "print uniwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams sv2014\n",
      "                        0         1\n",
      "0             (big, data)  0.002805\n",
      "1     (machine, learning)  0.002550\n",
      "2          (open, source)  0.002295\n",
      "3         (scikit, learn)  0.002295\n",
      "4     (ipython, notebook)  0.002040\n",
      "5     (high, performance)  0.001785\n",
      "6        (data, analysis)  0.001530\n",
      "7         (data, science)  0.001530\n",
      "8           (high, level)  0.001530\n",
      "9            (k, nearest)  0.001530\n",
      "10    (nearest, neighbor)  0.001530\n",
      "11  (neighbor, algorithm)  0.001530\n",
      "12           (real, time)  0.001530\n",
      "13     (reference, model)  0.001530\n",
      "14         (using, bokeh)  0.001530\n",
      "\n",
      "\n",
      "\n",
      "Bigrams ldn2014\n",
      "                           0         1\n",
      "0         (data, processing)  0.001969\n",
      "1        (machine, learning)  0.001969\n",
      "2            (data, science)  0.001312\n",
      "3                (data, set)  0.001312\n",
      "4             (open, source)  0.001312\n",
      "5                (python, r)  0.001312\n",
      "6             (python, used)  0.001312\n",
      "7            (scikit, learn)  0.001312\n",
      "8              (use, python)  0.001312\n",
      "9              (com, vstoxx)  0.000984\n",
      "10            (data, mining)  0.000984\n",
      "11  (derivatives, analytics)  0.000984\n",
      "12        (eurexchange, com)  0.000984\n",
      "13    (financial, analytics)  0.000984\n",
      "14     (financial, industry)  0.000984\n",
      "\n",
      "\n",
      "\n",
      "Bigrams berlin2014\n",
      "                      0         1\n",
      "0   (machine, learning)  0.002329\n",
      "1      (data, analysis)  0.002070\n",
      "2           (big, data)  0.001811\n",
      "3    (data, processing)  0.001811\n",
      "4          (real, time)  0.001552\n",
      "5   (ipython, notebook)  0.001294\n",
      "6   (knowledge, python)  0.001294\n",
      "7        (open, source)  0.001294\n",
      "8   (processing, large)  0.001294\n",
      "9       (scikit, learn)  0.001294\n",
      "10       (coming, soon)  0.001035\n",
      "11          (csv, json)  0.001035\n",
      "12       (data, driven)  0.001035\n",
      "13      (data, science)  0.001035\n",
      "14       (data, source)  0.001035\n",
      "\n",
      "\n",
      "\n",
      "Bigrams nyc2013\n",
      "                         0         1\n",
      "0      (machine, learning)  0.008183\n",
      "1          (scikit, learn)  0.005168\n",
      "2           (coming, soon)  0.003445\n",
      "3         (data, analysis)  0.002153\n",
      "4           (chip, design)  0.001723\n",
      "5          (data, science)  0.001723\n",
      "6        (image, features)  0.001723\n",
      "7      (ipython, notebook)  0.001723\n",
      "8           (open, source)  0.001723\n",
      "9              (scidb, py)  0.001723\n",
      "10      (data, scientists)  0.001292\n",
      "11  (learning, algorithms)  0.001292\n",
      "12       (learning, tasks)  0.001292\n",
      "13          (models, like)  0.001292\n",
      "14          (talk, covers)  0.001292\n",
      "\n",
      "\n",
      "\n",
      "Bigrams nyc2014\n",
      "                          0         1\n",
      "0       (machine, learning)  0.004188\n",
      "1           (data, science)  0.003290\n",
      "2           (scikit, learn)  0.003290\n",
      "3            (open, source)  0.002692\n",
      "4               (big, data)  0.001496\n",
      "5            (coming, soon)  0.001197\n",
      "6        (data, processing)  0.001197\n",
      "7              (data, sets)  0.001197\n",
      "8       (python, ecosystem)  0.001197\n",
      "9          (cloud, foundry)  0.000897\n",
      "10          (command, line)  0.000897\n",
      "11         (data, analysis)  0.000897\n",
      "12         (deep, learning)  0.000897\n",
      "13  (financial, statements)  0.000897\n",
      "14        (languages, like)  0.000897\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "\n",
    "for conference in words:\n",
    "    print \"Bigrams \" + str(conference)\n",
    "    finder = BigramCollocationFinder.from_words(words[conference])\n",
    "    scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    print pd.DataFrame(scored[:15])\n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(words)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('berlin2014', 'nyc2013'), 0.2),\n",
       " (('ldn2014', 'berlin2014'), 0.2),\n",
       " (('nyc2013', 'nyc2014'), 0.2),\n",
       " (('sv2014', 'ldn2014'), 0.2)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
